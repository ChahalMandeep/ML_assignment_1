{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"dataset - Sheet1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Class</th>\n",
       "      <th>Actual Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted Class  Actual Class\n",
       "0                0             0\n",
       "1                0             0\n",
       "2                1             0\n",
       "3                0             0\n",
       "4                0             0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 160 entries, 0 to 159\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count  Dtype\n",
      "---  ------           --------------  -----\n",
      " 0   Predicted Class  160 non-null    int64\n",
      " 1   Actual Class     160 non-null    int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 2.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=df['Predicted Class'].unique()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp=df[df['Actual Class'] == df['Predicted Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Class</th>\n",
       "      <th>Actual Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted Class  Actual Class\n",
       "0                0             0\n",
       "1                0             0\n",
       "3                0             0\n",
       "4                0             0\n",
       "8                0             0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Therefore total number of correct prediction is 121 out of 160"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7333333333333333"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy=121/165\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp0=df[(df['Actual Class'] ==0) & (df['Predicted Class']==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp1=df[(df['Actual Class'] ==1) & (df['Predicted Class']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp2=df[(df['Actual Class'] ==2) & (df['Predicted Class']==2)]\n",
    "tp2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp3=df[(df['Actual Class'] ==3) & (df['Predicted Class']==3)]\n",
    "tp3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp01=df[(df['Actual Class'] ==0) & (df['Predicted Class']==1)]\n",
    "tp01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp02=df[(df['Actual Class'] ==0) & (df['Predicted Class']==2)]\n",
    "tp02.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp03=df[(df['Actual Class'] ==0) & (df['Predicted Class']==3)]\n",
    "tp03.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "(3, 2)\n",
      "(0, 2)\n"
     ]
    }
   ],
   "source": [
    "tp10=df[(df['Actual Class'] ==1) & (df['Predicted Class']==0)]\n",
    "print(tp10.shape)\n",
    "tp12=df[(df['Actual Class'] ==1) & (df['Predicted Class']==2)]\n",
    "print(tp12.shape)\n",
    "tp13=df[(df['Actual Class'] ==1) & (df['Predicted Class']==3)]\n",
    "print(tp13.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "(2, 2)\n",
      "(6, 2)\n"
     ]
    }
   ],
   "source": [
    "tp20=df[(df['Actual Class'] ==2) & (df['Predicted Class']==0)]\n",
    "print(tp10.shape)\n",
    "tp22=df[(df['Actual Class'] ==2) & (df['Predicted Class']==1)]\n",
    "print(tp22.shape)\n",
    "tp23=df[(df['Actual Class'] ==2) & (df['Predicted Class']==3)]\n",
    "print(tp23.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "(3, 2)\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "tp30=df[(df['Actual Class'] ==3) & (df['Predicted Class']==0)]\n",
    "print(tp30.shape)\n",
    "tp31=df[(df['Actual Class'] ==3) & (df['Predicted Class']==1)]\n",
    "print(tp31.shape)\n",
    "tp32=df[(df['Actual Class'] ==3) & (df['Predicted Class']==2)]\n",
    "print(tp32.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.b\n",
    "\n",
    "# Here is the confusion matrix"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "               predicted\n",
    "               0   1   2   3\n",
    "          \n",
    "           0   33  8   4   4\n",
    "           \n",
    "           1   1   32  3   0\n",
    " actual          \n",
    "           2   1   2   29  6\n",
    "           \n",
    "           3   2   3   3   27\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75625"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_accuracy=(33+32+29+27)/160\n",
    "overall_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75625"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "121/160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.673469387755102"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class0_accuracy=33/(33+8+4+4)\n",
    "class0_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class1_accuracy=32/(1+32+3+0)\n",
    "class1_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7631578947368421"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2_accuracy=29/(1+2+29+6)\n",
    "class2_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7714285714285715"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class3_accuracy=27/(2+3+3+27)\n",
    "class3_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            predicted\n",
    "               0   1   2   3\n",
    "          \n",
    "           0   33  8   4   4\n",
    "           \n",
    "           1   1   32  3   0\n",
    " actual          \n",
    "           2   1   2   29  6\n",
    "           \n",
    "           3   2   3   3   27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp0=33\n",
    "tn0=32+3+2+3+29+6+3+27\n",
    "fp0=1+1+2\n",
    "fn0=8+4+4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have all the necessary metrics for class 0 from the confusion matrix, now we can calculate the performance measures for class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8918918918918919\n",
      "0.673469387755102\n"
     ]
    }
   ],
   "source": [
    "precision0=tp0/(tp0+fp0)\n",
    "print(precision0)\n",
    "recall0=tp0/(tp0+fn0)\n",
    "print(recall0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-56-1f6804643b41>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-56-1f6804643b41>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    0   1   2   3\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "              predicted\n",
    "               0   1   2   3\n",
    "          \n",
    "           0   33  8   4   4\n",
    "           \n",
    "           1   1   32  3   0\n",
    " actual          \n",
    "           2   1   2   29  6\n",
    "           \n",
    "           3   2   3   3   27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp1=32\n",
    "tn1=33+4+4+1+2+29+6+27+3\n",
    "fp1=8+2+3\n",
    "fn1=1+3+0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7111111111111111\n",
      "0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "precision1=tp1/(tp1+fp1)\n",
    "print(precision1)\n",
    "recall1=tp1/(tp1+fn1)\n",
    "print(recall1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "              predicted\n",
    "               0   1   2   3\n",
    "          \n",
    "           0   33  8   4   4\n",
    "           \n",
    "           1   1   32  3   0\n",
    " actual          \n",
    "           2   1   2   29  6\n",
    "           \n",
    "           3   2   3   3   27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp2=29\n",
    "tn2=33+8+4+1+32+0+2+3+27\n",
    "fp2=4+3+3\n",
    "fn2=1+2+6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7435897435897436\n",
      "0.7631578947368421\n"
     ]
    }
   ],
   "source": [
    "precision2=tp2/(tp2+fp2)\n",
    "print(precision2)\n",
    "recall2=tp2/(tp2+fn2)\n",
    "print(recall2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-65-1f6804643b41>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-65-1f6804643b41>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    0   1   2   3\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "              predicted\n",
    "               0   1   2   3\n",
    "          \n",
    "           0   33  8   4   4\n",
    "           \n",
    "           1   1   32  3   0\n",
    " actual          \n",
    "           2   1   2   29  6\n",
    "           \n",
    "           3   2   3   3   27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp3=27\n",
    "tn3=33+8+4+1+32+3+1+2+29\n",
    "fp3=4+0+6\n",
    "fn3=2+3+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7297297297297297\n",
      "0.7714285714285715\n"
     ]
    }
   ],
   "source": [
    "precision3=tp3/(tp3+fp3)\n",
    "print(precision3)\n",
    "recall3=tp3/(tp3+fn3)\n",
    "print(recall3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Macro_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "macro-avg is mean average macro-avg is mean average precision/recall of all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7690806190806191"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "macro_avg_precision=(precision0+precision1+precision2+precision3)/4\n",
    "macro_avg_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7742361857023511"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_avg_recall=(recall0+recall1+recall2+recall3)/4\n",
    "macro_avg_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights for each class are the total number of samples of that class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7791117310104652"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_avg_precision=(precision0*49+precision1*36+precision2*38+precision3*35)/(49+36+38+35)\n",
    "weighted_avg_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7658227848101266"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_avg_recall=(recall0*49+recall1*36+recall2*38+recall3*35)/(49+36+38+35)\n",
    "weighted_avg_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F-1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7674418604651163"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class0_f1=2*(precision0*recall0)/(precision0+recall0)\n",
    "class0_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7901234567901234"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class1_f1=2*(precision1*recall1)/(precision1+recall1)\n",
    "class1_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7532467532467534"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2_f1=2*(precision2*recall2)/(precision2+recall2)\n",
    "class2_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class3_f1=2*(precision3*recall3)/(precision3+recall3)\n",
    "class3_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03669724770642202\n",
      "0.32653061224489793\n"
     ]
    }
   ],
   "source": [
    "class0_type_1=fp0/(fp0+tn0)\n",
    "print(class0_type_1)\n",
    "class0_type_2=fn0/(fn0+tp0)\n",
    "print(class0_type_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10655737704918032\n",
      "0.1111111111111111\n"
     ]
    }
   ],
   "source": [
    "class1_type_1=fp1/(fp1+tn1)\n",
    "print(class1_type_1)\n",
    "class1_type_2=fn1/(fn1+tp1)\n",
    "print(class1_type_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08333333333333333\n",
      "0.23684210526315788\n"
     ]
    }
   ],
   "source": [
    "class2_type_1=fp2/(fp2+tn2)\n",
    "print(class2_type_1)\n",
    "class2_type_2=fn2/(fn2+tp2)\n",
    "print(class2_type_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08130081300813008\n",
      "0.22857142857142856\n"
     ]
    }
   ],
   "source": [
    "class3_type_1=fp3/(fp3+tn3)\n",
    "print(class3_type_1)\n",
    "class3_type_2=fn3/(fn3+tp3)\n",
    "print(class3_type_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['Actual Class'].values.reshape(-1,1)\n",
    "X.ndim\n",
    "#X=X.reshape(-1,1)\n",
    "#y = df['Predicted Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[ 6  0  1  0]\n",
      " [ 1  9  1  1]\n",
      " [ 1  1 10  1]\n",
      " [ 2  0  1  5]]\n",
      "\n",
      "Accuracy: 0.75\n",
      "\n",
      "Macro Precision: 0.75\n",
      "Macro Recall: 0.75\n",
      "Macro F1-score: 0.74\n",
      "\n",
      "Weighted Precision: 0.77\n",
      "Weighted Recall: 0.75\n",
      "Weighted F1-score: 0.75\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.60      0.86      0.71         7\n",
      "     Class 1       0.90      0.75      0.82        12\n",
      "     Class 2       0.77      0.77      0.77        13\n",
      "     Class 3       0.71      0.62      0.67         8\n",
      "\n",
      "    accuracy                           0.75        40\n",
      "   macro avg       0.75      0.75      0.74        40\n",
      "weighted avg       0.77      0.75      0.75        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df['Actual Class'].values.reshape(-1,1)\n",
    "\n",
    "y = df['Predicted Class']\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "svc = SVC(kernel='rbf', C=1).fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "#importing confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "#importing accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_test, y_pred, target_names=['Class 0','Class 1', 'Class 2', 'Class 3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 1)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparision Table between sklearn output and standard output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    Class 0       0.60/.89                          0.86/.67                      0.71/.76\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "Camparison Report                                                 \n",
    "\n",
    "\n",
    "\n",
    "              precision_sklearn/standard   recall_sklearn/standard  f1-score_sklearn/standard    \n",
    "\n",
    "     Class 0       0.60/.89                          0.86/.67                      0.71/.76        \n",
    "     Class 1       0.90/.71                          0.75/.88                      0.82/.79        \n",
    "     Class 2       0.77/.74                         0.77/.76                      0.77/.75        \n",
    "     Class 3       0.71/.72                         0.62/.77                      0.67/.75         \n",
    "\n",
    "    accuracy                           0.75/.75        \n",
    "   macro avg       0.75/.76      0.75/.77      0.74/.74        \n",
    "weighted avg       0.77/.77      0.75/.76      0.75/.75        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
